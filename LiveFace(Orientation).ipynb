{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_virtual_device_configuration(\n",
    "        physical_devices[0],\n",
    "        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=2000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from imutils import face_utils\n",
    "import dlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/prabhanshu/.local/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "std = joblib.load('std.mod')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face_points(image,detector,predictor):\n",
    "    \n",
    "    face_rect = detector(image, 0)\n",
    "    if len(face_rect) != 1: return []\n",
    "    \n",
    "    dlib_points = predictor(image, face_rect[0])\n",
    "    face_points = []\n",
    "    for i in range(68):\n",
    "        x, y = dlib_points.part(i).x, dlib_points.part(i).y\n",
    "        face_points.append(np.array([x, y]))\n",
    "    return face_points\n",
    "        \n",
    "def compute_features(face_points):\n",
    "    assert (len(face_points) == 68), \"len(face_points) must be 68\"\n",
    "    \n",
    "    face_points = np.array(face_points)\n",
    "    features = []\n",
    "    for i in range(68):\n",
    "        for j in range(i+1, 68):\n",
    "            features.append(np.linalg.norm(face_points[i]-face_points[j]))\n",
    "            \n",
    "    return np.array(features).reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################################################\n",
      "#################################################\n",
      "#################################################\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from PyQt5.QtCore import QTimer\n",
    "model = load_model('Posmodel.h5')\n",
    "p = \"shape_predictor_68_face_landmarks.dat\"\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(p)\n",
    "pts=[1,4,6,8,10,12,14,17,27,25,23,28,22,20,18,37,40,43,46,32,34,36,49,52,55,58]\n",
    "cn=False\n",
    "tm1=False\n",
    "ri= False\n",
    "tm2=False\n",
    "le=False\n",
    "tm3=False\n",
    "y1=0\n",
    "cfi=0\n",
    "rfi=0\n",
    "lfi=0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, 800)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 600)\n",
    " \n",
    "while True:\n",
    "    # Getting out image by webcam \n",
    "    ctime=int(time.time())\n",
    "    _, image = cap.read()\n",
    "    image = cv2.flip(image, 1)\n",
    "    imgFr = image.copy()\n",
    "\n",
    "    # Converting the image to gray scale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    size = image.shape\n",
    "    face_points = detect_face_points(gray,detector,predictor)\n",
    "    if (cn == True ):\n",
    "        try:\n",
    "            cv2.line(image,(face_points[21][0],face_points[21][1]),(face_points[27][0],face_points[27][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[22][0],face_points[22][1]),(face_points[27][0],face_points[27][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[39][0],face_points[39][1]),(face_points[27][0],face_points[27][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[42][0],face_points[42][1]),(face_points[27][0],face_points[27][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[27][0],face_points[27][1]),(face_points[31][0],face_points[31][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[27][0],face_points[27][1]),(face_points[35][0],face_points[35][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[31][0],face_points[31][1]),(face_points[33][0],face_points[33][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[35][0],face_points[35][1]),(face_points[33][0],face_points[33][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[31][0],face_points[31][1]),(face_points[48][0],face_points[48][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[35][0],face_points[35][1]),(face_points[54][0],face_points[54][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[48][0],face_points[48][1]),(face_points[51][0],face_points[51][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[54][0],face_points[54][1]),(face_points[51][0],face_points[51][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[48][0],face_points[48][1]),(face_points[57][0],face_points[57][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[54][0],face_points[54][1]),(face_points[57][0],face_points[57][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[7][0],face_points[7][1]),(face_points[57][0],face_points[57][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[9][0],face_points[9][1]),(face_points[57][0],face_points[57][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[7][0],face_points[7][1]),(face_points[9][0],face_points[9][1]), (255, 255, 255), 1)\n",
    "            \n",
    "        except:\n",
    "            print(\"Face Nnot Found\")\n",
    "            \n",
    "            \n",
    "            \n",
    "    if (ri == True ):\n",
    "        try:\n",
    "            cv2.line(image,(face_points[22][0],face_points[22][1]),(face_points[24][0],face_points[24][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[24][0],face_points[24][1]),(face_points[26][0],face_points[26][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[26][0],face_points[26][1]),(face_points[16][0],face_points[16][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[45][0],face_points[45][1]),(face_points[16][0],face_points[16][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[16][0],face_points[16][1]),(face_points[13][0],face_points[13][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[35][0],face_points[35][1]),(face_points[13][0],face_points[13][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[13][0],face_points[13][1]),(face_points[11][0],face_points[11][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[54][0],face_points[54][1]),(face_points[11][0],face_points[11][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[11][0],face_points[11][1]),(face_points[9][0],face_points[9][1]), (255, 255, 255), 1)\n",
    "        except:\n",
    "            print(\"Face Nnot Found\")\n",
    "            \n",
    "    if (le == True ):\n",
    "        try:\n",
    "            cv2.line(image,(face_points[21][0],face_points[21][1]),(face_points[19][0],face_points[19][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[19][0],face_points[19][1]),(face_points[17][0],face_points[17][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[17][0],face_points[17][1]),(face_points[0][0],face_points[0][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[36][0],face_points[36][1]),(face_points[0][0],face_points[0][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[0][0],face_points[0][1]),(face_points[3][0],face_points[3][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[31][0],face_points[31][1]),(face_points[3][0],face_points[3][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[3][0],face_points[3][1]),(face_points[5][0],face_points[5][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[48][0],face_points[48][1]),(face_points[5][0],face_points[5][1]), (255, 255, 255), 1)\n",
    "            cv2.line(image,(face_points[5][0],face_points[5][1]),(face_points[7][0],face_points[7][1]), (255, 255, 255), 1)\n",
    "        except:\n",
    "            print(\"Face Nnot Found\")\n",
    "        \n",
    "    \n",
    "    #print(face_points[28][0] )\n",
    "    #cv2.circle(image, (face_points[28][0],face_points[28][1]), 1, (255, 255, 255), -1)\n",
    "\n",
    "    \n",
    "    if (len(face_points) == 68):    \n",
    "    \n",
    "        features = compute_features(face_points)\n",
    "        features = std.transform(features)\n",
    "        y_pred = model.predict(features)\n",
    "\n",
    "        roll_pred, pitch_pred, yaw_pred = y_pred[0]\n",
    "        ##########################################################################\n",
    "        roll_pred=float(roll_pred)+1.6\n",
    "        pitch_pred=float(pitch_pred)-3.0\n",
    "        yaw_pred=float(yaw_pred)-4.0\n",
    "        \n",
    "        ##########################################################################\n",
    "        #print(roll_pred)\n",
    "        cv2.putText(image, ' Roll: '+str(roll_pred), (50,30), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, 'Pitch: '+str(pitch_pred), (50,60), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "        cv2.putText(image, '  Yaw: '+str(yaw_pred), (50,90), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "        \n",
    "        if (-5 <=yaw_pred<=5 and cn == False):\n",
    "            if(tm1==False):\n",
    "                ltimec=int(time.time())\n",
    "                tm1= True\n",
    "                \n",
    "            cv2.imwrite(\"tifr/frc%d.jpg\" %cfi,imgFr)\n",
    "            cfi=cfi+1\n",
    "           \n",
    "\n",
    "            if(abs(ctime - ltimec) >=2):\n",
    "                print(\"#################################################\")\n",
    "                \n",
    "                cn= True\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            cfi=0\n",
    "            tm1=False\n",
    "            \n",
    "            \n",
    "            \n",
    "\n",
    "        if (-20<yaw_pred < -10 and ri == False):\n",
    "            if(tm2==False):\n",
    "                ltimer=int(time.time())\n",
    "                tm2= True\n",
    "                \n",
    "            cv2.imwrite(\"tifr/frr%d.jpg\" %rfi,imgFr)\n",
    "            rfi=rfi+1\n",
    "           \n",
    "\n",
    "            if(abs(ctime - ltimer) >=2):\n",
    "                print(\"#################################################\")\n",
    "                \n",
    "                ri= True\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            rfi=0\n",
    "            tm2=False\n",
    "            \n",
    "            \n",
    "            \n",
    "        if (20>yaw_pred> 10 and le == False):\n",
    "            if(tm3==False):\n",
    "                ltimel=int(time.time())\n",
    "                tm3= True\n",
    "                \n",
    "            cv2.imwrite(\"tifr/frl%d.jpg\" %lfi,imgFr)\n",
    "            lfi=lfi+1\n",
    "           \n",
    "\n",
    "            if(abs(ctime - ltimel) >=2):\n",
    "                print(\"#################################################\")\n",
    "                \n",
    "                le= True\n",
    "                \n",
    "                \n",
    "                \n",
    "        else:\n",
    "            lfi=0\n",
    "            tm3=False\n",
    "        if(cn== True and le== True and ri==True):\n",
    "            cv2.putText(image, \"Live Face\", (450,400), cv2.FONT_HERSHEY_SIMPLEX , 1, (0, 255, 0) , 2, cv2.LINE_AA)\n",
    "            \n",
    "        cv2.imshow(\"Output\", image)\n",
    "        #cv2.putText(image, ' Roll: {:.5f}°'.format(roll_pred), (50,30), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "        #cv2.putText(image, 'Pitch: {:.2f}°'.format(pitch_pred), (50,60), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "        #cv2.putText(image, '  Yaw: {:.2f}°'.format(yaw_pred), (50,90), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "    #fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    #cv2.putText(image, \" video.get(cv2.CAP_PROP_FPS) : {0}\".format(fps), (10,90), cv2.FONT_HERSHEY_SIMPLEX , 1, (255, 0, 0) , 2, cv2.LINE_AA)\n",
    "    \n",
    "    else:\n",
    "        cv2.imshow(\"Output\", image)\n",
    "    #cv2.imshow(\"Output\", image)\n",
    "    #cv2.imshow(\"Output2\", img)\n",
    "    \n",
    "    k = cv2.waitKey(5) & 0xFF\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
